{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwbarbona/labo2025v/blob/main/LSTM_avanzado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Primero seleccionar Runtime T4 GPU**\n",
        "\n",
        "*La utilizaremos para obtener tiempos razonables de ejecución.*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GyLzARtU2huz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_install_tf"
      },
      "outputs": [],
      "source": [
        "# Instalar TensorFlow si no está disponible (necesario en entornos nuevos de Colab)\n",
        "!pip install tensorflow -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTOxYfMa7sDZ"
      },
      "source": [
        "# Modelos Encoder-Decoder para Traducción Automática\n",
        "\n",
        "En este cuaderno se explora la implementación de una arquitectura encoder-decoder utilizando redes LSTM para tareas de traducción automática de inglés a español. Se emplea un corpus paralelo del Proyecto Tatoeba.\n",
        "\n",
        "## Objetivos de Aprendizaje\n",
        "- Comprender la arquitectura encoder-decoder para tareas secuencia a secuencia.\n",
        "- Preprocesar datos de texto paralelos para traducción automática.\n",
        "- Implementar un encoder y decoder basado en LSTM.\n",
        "- Entrenar el modelo utilizando teacher forcing.\n",
        "- Realizar inferencia con el modelo entrenado.\n",
        "- Evaluar la calidad de la traducción de manera cualitativa.\n",
        "\n",
        "**Nota:** Este es un ejemplo simplificado con fines didácticos. En la práctica, se utilizan técnicas más avanzadas como mecanismos de atención y búsqueda en haz para un mejor rendimiento.\n",
        "\n",
        "**Conceptos Clave a Recordar:**\n",
        "- **Encoder-Decoder:** El encoder comprime la entrada en un vector de contexto; el decoder genera la salida a partir de este vector.\n",
        "- **Teacher Forcing:** Técnica de entrenamiento donde se proporciona la salida real anterior en lugar de la predicha.\n",
        "- **Inferencia:** Proceso autoregresivo para generar traducciones token por token.\n",
        "\n",
        "**Pregunta para Reflexión:** ¿Por qué la arquitectura encoder-decoder es adecuada para tareas como la traducción, donde las longitudes de entrada y salida pueden diferir?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new_section_problem"
      },
      "source": [
        "## Explicación Detallada del Problema\n",
        "\n",
        "La traducción automática consiste en convertir texto de un idioma a otro utilizando una máquina, sin intervención humana directa. Imagínese tener una conversación con alguien que habla otro idioma: en lugar de buscar un diccionario o un traductor humano, un sistema podría traducir al instante las palabras para que ambos se entiendan.\n",
        "\n",
        "En términos simples, este problema se parece a convertir una receta en inglés a español, manteniendo el significado original. Es útil en el mundo real para viajar, negocios internacionales o acceder a información en idiomas extranjeros, facilitando la comunicación global. Aquí, se utiliza un conjunto de datos con oraciones en inglés y sus equivalentes en español para entrenar un modelo que 'aprenda' a traducir, de forma accesible y sin necesidad de conocimientos técnicos profundos para captar la idea básica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlCx_vPA7sDc"
      },
      "source": [
        "## 1. Importación de Bibliotecas\n",
        "\n",
        "**Explicación:** Estas bibliotecas son esenciales para el preprocesamiento, modelado y visualización. TensorFlow y Keras facilitan la construcción de modelos recurrentes, mientras que NumPy y Pandas ayudan en el manejo de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZm__pgv7sDd"
      },
      "outputs": [],
      "source": [
        "# Importación de bibliotecas para expresiones regulares y datos numéricos\n",
        "import re  # Para limpieza de texto mediante expresiones regulares\n",
        "import numpy as np  # Para operaciones con arreglos y matrices\n",
        "import pandas as pd  # Para manipulación de datos tabulares\n",
        "import os  # Para chequeos de archivos\n",
        "\n",
        "# Bibliotecas para aprendizaje profundo\n",
        "import tensorflow as tf  # Framework principal\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense  # Capas del modelo\n",
        "from tensorflow.keras.models import Model  # Para definir modelos\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # Para tokenización\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Para relleno de secuencias\n",
        "from sklearn.model_selection import train_test_split  # Para división de datos\n",
        "\n",
        "# Bibliotecas para visualización\n",
        "import matplotlib.pyplot as plt  # Para gráficos\n",
        "import random  # Para selección aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_gpu_check"
      },
      "outputs": [],
      "source": [
        "# Verificar disponibilidad de GPU para aceleración\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "    print(\"GPU detectada: El entrenamiento se acelerará automáticamente.\")\n",
        "else:\n",
        "    print(\"No se detectó GPU: El entrenamiento usará CPU (más lento). Cambie el tipo de runtime en Colab a GPU para mejorar el rendimiento.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vSBQM0L7sDe"
      },
      "source": [
        "## 2. Carga y Exploración del Conjunto de Datos\n",
        "\n",
        "Se utiliza el corpus paralelo inglés-español de http://www.manythings.org/anki/\n",
        "\n",
        "**Explicación:** La carga de datos paralelos es fundamental en traducción automática, ya que cada oración en un idioma corresponde a su equivalente en el otro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmMr7cSR7sDe"
      },
      "outputs": [],
      "source": [
        "# Chequea si spa-eng.zip ya fue descargado\n",
        "if not os.path.exists(\"spa-eng.zip\"):\n",
        "    # Descarga y descompresión del archivo\n",
        "    !wget http://www.manythings.org/anki/spa-eng.zip\n",
        "    !unzip spa-eng.zip -d spa-eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3OjTHXb7sDf"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo de datos\n",
        "ruta_datos = 'spa-eng/spa.txt'\n",
        "# Lectura del archivo\n",
        "with open(ruta_datos, 'r', encoding='utf-8') as f:\n",
        "    líneas = f.read().split('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new_section_dataset"
      },
      "source": [
        "## Recorrido por el Conjunto de Datos\n",
        "\n",
        "El conjunto de datos Tatoeba consta de pares de oraciones en inglés y español, con aproximadamente 120.000 ejemplos. Cada línea del archivo contiene una oración en inglés, su traducción al español y metadatos separados por tabuladores.\n",
        "\n",
        "**Estructura:**\n",
        "- Líneas del archivo: Oración en inglés \\t Oración en español \\t Atribución.\n",
        "- Después de carga: Listas de textos en inglés y español.\n",
        "\n",
        "**Contenidos:** Las oraciones cubren conversaciones cotidianas, frases simples y complejas, ideales para aprender patrones lingüísticos.\n",
        "\n",
        "**Relación con la Solución:** Este corpus paralelo permite que el modelo encoder-decoder aprenda a mapear secuencias de un idioma a otro. El preprocesamiento (limpieza, tokenización) prepara los datos para que el modelo capture dependencias secuenciales y genere traducciones coherentes.\n",
        "\n",
        "**Ejemplos Adicionales:**\n",
        "A continuación se muestran más pares de oraciones para ilustrar el contenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_code_dataset"
      },
      "outputs": [],
      "source": [
        "# Impresión de más ejemplos\n",
        "print(\"Ejemplo de línea 1:\", líneas[0])\n",
        "print(\"Ejemplo de línea 2:\", líneas[1])\n",
        "print(\"Ejemplo de línea 3:\", líneas[2])\n",
        "\n",
        "# Número total de líneas\n",
        "print(\"\\nNúmero total de pares:\", len(líneas) - 1)  # Menos uno por posible línea vacía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqHAR-6I7sDf"
      },
      "source": [
        "### Muestra de Datos\n",
        "\n",
        "**Explicación:** Visualizar muestras ayuda a verificar la integridad del corpus y entender su estructura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97cXY1EI7sDg"
      },
      "outputs": [],
      "source": [
        "# Lista para pares de muestras\n",
        "pares_muestras = []\n",
        "# Procesamiento de las primeras 10 líneas\n",
        "for línea in líneas[:10]:\n",
        "    if '\\t' in línea:\n",
        "        ing, esp, _ = línea.split('\\t')  # Separación por tabulador\n",
        "        pares_muestras.append((ing, esp))\n",
        "\n",
        "# Creación de DataFrame para visualización\n",
        "df_muestras = pd.DataFrame(pares_muestras, columns=['Inglés', 'Español'])\n",
        "print(\"Una Mirada al Corpus Paralelo:\")\n",
        "display(df_muestras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Tu_7hG7sDg"
      },
      "source": [
        "## 3. Preprocesamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC43Wglh7sDh"
      },
      "source": [
        "### Función de Limpieza de Texto\n",
        "\n",
        "**Explicación:** La limpieza elimina ruido como puntuación mal colocada y caracteres no deseados, facilitando la tokenización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNeepG657sDh"
      },
      "outputs": [],
      "source": [
        "# Función para limpiar texto\n",
        "def limpiar_texto(t):\n",
        "    t = re.sub(r\"([?.!,¿])\", r\" \\1 \", t)  # Separar puntuación\n",
        "    t = re.sub(r'[\" \"]+', \" \", t)  # Normalizar espacios\n",
        "    t = re.sub(r\"[^a-zA-Z?.!,¿¿]+\", \" \", t)  # Eliminar caracteres no alfabéticos ni puntuación\n",
        "    t = t.strip()  # Eliminar espacios iniciales/finales\n",
        "    return t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-6fWAn57sDh"
      },
      "source": [
        "Se agrega un token `start` al inicio y `end` al final de cada oración objetivo (español). Estos tokens actúan como señales explícitas, transformando la tarea de predecir el objetivo dado la fuente, en un proceso estructurado de predecir el siguiente token dado la fuente y todos los tokens generados previamente.\n",
        "\n",
        "**Pregunta para Reflexión:** ¿Cómo afectan estos tokens al proceso de inferencia?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BqaYmIp7sDh"
      },
      "outputs": [],
      "source": [
        "# Función para crear el conjunto de datos\n",
        "def crear_conjunto_datos(ruta, num_ejemplos):\n",
        "    líneas = open(ruta, encoding='UTF-8').read().strip().split('\\n')  # Lectura y división\n",
        "    pares_palabras = [[limpiar_texto(s) for s in l.split('\\t')[:2]] for l in líneas[:num_ejemplos]]  # Limpieza\n",
        "\n",
        "    # Agregar tokens de inicio y fin al idioma objetivo\n",
        "    for par in pares_palabras:\n",
        "        par[1] = 'start ' + par[1] + ' end'\n",
        "\n",
        "    return zip(*pares_palabras)\n",
        "\n",
        "# Uso de un subconjunto para entrenamiento rápido\n",
        "num_ejemplos = 10000  # Reducido para ejecución rápida en clase; en casa usar 30000 o más\n",
        "texto_entrada, texto_objetivo = crear_conjunto_datos(ruta_datos, num_ejemplos)\n",
        "\n",
        "print(\"Par de Muestra Preprocesado:\")\n",
        "print(\"Entrada (Inglés):\", texto_entrada[0])\n",
        "print(\"Objetivo (Español):\", texto_objetivo[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSguEzQ87sDi"
      },
      "source": [
        "## 4. Tokenización\n",
        "\n",
        "**Explicación:** La tokenización convierte texto en secuencias numéricas, esenciales para el procesamiento por redes neuronales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSbNbo_X7sDi"
      },
      "outputs": [],
      "source": [
        "# Tokenizador para entrada\n",
        "tokenizador_entrada = Tokenizer()\n",
        "tokenizador_entrada.fit_on_texts(texto_entrada)  # Ajuste al texto\n",
        "tensor_entrada = tokenizador_entrada.texts_to_sequences(texto_entrada)  # Conversión a secuencias\n",
        "\n",
        "# Tokenizador para objetivo\n",
        "tokenizador_objetivo = Tokenizer()\n",
        "tokenizador_objetivo.fit_on_texts(texto_objetivo)\n",
        "tensor_objetivo = tokenizador_objetivo.texts_to_sequences(texto_objetivo)\n",
        "\n",
        "# Tamaños de vocabulario\n",
        "tamaño_vocab_entrada = len(tokenizador_entrada.word_index) + 1\n",
        "tamaño_vocab_objetivo = len(tokenizador_objetivo.word_index) + 1\n",
        "\n",
        "print(f\"Tamaño de vocabulario de entrada: {tamaño_vocab_entrada}\")\n",
        "print(f\"Tamaño de vocabulario de objetivo: {tamaño_vocab_objetivo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNVp2mIa7sDi"
      },
      "source": [
        "## 5. Relleno de Secuencias\n",
        "\n",
        "**Explicación:** El relleno asegura que todas las secuencias tengan la misma longitud para procesar en lotes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs1O2iRV7sDj"
      },
      "outputs": [],
      "source": [
        "# Función para rellenar secuencias\n",
        "def rellenar_secuencias(tensor):\n",
        "    return pad_sequences(tensor, padding='post')  # Relleno al final\n",
        "\n",
        "tensor_entrada_rellenado = rellenar_secuencias(tensor_entrada)\n",
        "tensor_objetivo_rellenado = rellenar_secuencias(tensor_objetivo)\n",
        "\n",
        "longitud_máx_entrada = tensor_entrada_rellenado.shape[1]\n",
        "longitud_máx_objetivo = tensor_objetivo_rellenado.shape[1]\n",
        "\n",
        "print(f\"Longitud máxima de secuencias de entrada: {longitud_máx_entrada}\")\n",
        "print(f\"Longitud máxima de secuencias de objetivo: {longitud_máx_objetivo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySfP3q7G7sDj"
      },
      "source": [
        "## 6. Preparación de Datos para Teacher Forcing\n",
        "\n",
        "**Explicación:** Teacher forcing acelera el entrenamiento al proporcionar la salida correcta en cada paso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5O7k-x17sDj"
      },
      "outputs": [],
      "source": [
        "# Datos de entrada y objetivo para decoder\n",
        "datos_entrada_decoder = np.zeros((len(tensor_objetivo), longitud_máx_objetivo))\n",
        "datos_objetivo_decoder = np.zeros((len(tensor_objetivo), longitud_máx_objetivo))\n",
        "\n",
        "for i, obj_t in enumerate(tensor_objetivo):\n",
        "    datos_entrada_decoder[i, 0:len(obj_t)] = obj_t  # Secuencia completa\n",
        "    datos_objetivo_decoder[i, 0:len(obj_t)-1] = obj_t[1:]  # Secuencia desplazada\n",
        "    datos_objetivo_decoder[i, len(obj_t)-1:] = 0  # Relleno con ceros\n",
        "\n",
        "# División en conjuntos de entrenamiento y validación\n",
        "entrada_encoder_entren, entrada_encoder_val, entrada_decoder_entren, entrada_decoder_val, objetivo_decoder_entren, objetivo_decoder_val = train_test_split(\n",
        "    tensor_entrada_rellenado, datos_entrada_decoder, datos_objetivo_decoder, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new_section_lstm_demo"
      },
      "source": [
        "## Demostración Rápida de LSTM para Predicción de Series Temporales\n",
        "\n",
        "**Explicación:** Las LSTM no solo sirven para traducción, sino también para series temporales, donde capturan patrones en datos secuenciales como temperaturas o precios. Aquí se presenta un ejemplo simple con una serie sinusoidal para ilustrar su aplicación, si el tiempo en clase lo permite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_code_lstm_demo"
      },
      "outputs": [],
      "source": [
        "# Generación de datos sintéticos: onda sinusoidal\n",
        "time_steps = np.linspace(0, 10 * np.pi, 1000)\n",
        "data = np.sin(time_steps)\n",
        "\n",
        "# Preparación de secuencias para LSTM (ventana de 50 pasos para predecir el siguiente)\n",
        "def create_sequences(data, seq_length):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        xs.append(data[i:i + seq_length])\n",
        "        ys.append(data[i + seq_length])\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "SEQ_LENGTH = 50\n",
        "X, y = create_sequences(data, SEQ_LENGTH)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))  # Forma para LSTM\n",
        "\n",
        "# División en entrenamiento y prueba\n",
        "split = int(0.8 * len(X))\n",
        "X_train_ts, X_test_ts = X[:split], X[split:]\n",
        "y_train_ts, y_test_ts = y[:split], y[split:]\n",
        "\n",
        "# Construcción del modelo LSTM simple para series temporales\n",
        "model_ts = tf.keras.Sequential([\n",
        "    Input(shape=(SEQ_LENGTH, 1)),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model_ts.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Entrenamiento\n",
        "history_ts = model_ts.fit(X_train_ts, y_train_ts, epochs=2, validation_data=(X_test_ts, y_test_ts), verbose=1)  # Limitado a 2 épocas para ejecución rápida\n",
        "\n",
        "# Predicciones\n",
        "y_pred_ts = model_ts.predict(X_test_ts)\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test_ts, label='Valor Real')\n",
        "plt.plot(y_pred_ts, label='Predicción LSTM')\n",
        "plt.title('Predicción de Serie Temporal con LSTM')\n",
        "plt.xlabel('Muestras de Prueba')\n",
        "plt.ylabel('Valor')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('**Nota:** Esta demostración muestra cómo las LSTM capturan dependencias temporales, similar a cómo procesan secuencias en traducción.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYh0_AUs7sDk"
      },
      "source": [
        "## 7. Definición de Hiperparámetros del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwSXxO3nxGYa"
      },
      "outputs": [],
      "source": [
        "# Hiperparámetros del modelo\n",
        "dimensión_incrustacion = 256\n",
        "unidades_ocultas = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykcU6tOS7sDk"
      },
      "source": [
        "Ahora, se construirá el modelo pieza por pieza, comenzando con el encoder.\n",
        "\n",
        "**Explicación:** El encoder resume la entrada en estados ocultos, que el decoder usa para generar la salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytp3VjJU7sDk"
      },
      "outputs": [],
      "source": [
        "# 1. El Encoder\n",
        "entradas_encoder = Input(shape=(None,), name='entradas_encoder')  # Entrada variable\n",
        "capa_incrustacion_encoder = Embedding(tamaño_vocab_entrada, dimensión_incrustacion, name='incrustacion_encoder')\n",
        "incrustacion_encoder = capa_incrustacion_encoder(entradas_encoder)\n",
        "\n",
        "lstm_encoder = LSTM(unidades_ocultas, return_state=True, name='lstm_encoder')\n",
        "salidas_encoder, estado_h, estado_c = lstm_encoder(incrustacion_encoder)\n",
        "estados_encoder = [estado_h, estado_c]\n",
        "\n",
        "# 2. El Decoder\n",
        "entradas_decoder = Input(shape=(None,), name='entradas_decoder')\n",
        "capa_incrustacion_decoder = Embedding(tamaño_vocab_objetivo, dimensión_incrustacion, name='incrustacion_decoder')\n",
        "incrustacion_decoder = capa_incrustacion_decoder(entradas_decoder)\n",
        "\n",
        "lstm_decoder = LSTM(unidades_ocultas, return_sequences=True, return_state=True, name='lstm_decoder')\n",
        "salidas_decoder, _, _ = lstm_decoder(incrustacion_decoder, initial_state=estados_encoder)\n",
        "\n",
        "densa_decoder = Dense(tamaño_vocab_objetivo, activation='softmax', name='densa_decoder')\n",
        "salidas_decoder = densa_decoder(salidas_decoder)\n",
        "\n",
        "# 3. Ensamblaje del Modelo de Entrenamiento\n",
        "modelo_entrenamiento = Model([entradas_encoder, entradas_decoder], salidas_decoder)\n",
        "\n",
        "# Visualización de la arquitectura\n",
        "modelo_entrenamiento.summary()\n",
        "tf.keras.utils.plot_model(modelo_entrenamiento, to_file='modelo_entrenamiento.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xe58kQo7sDk"
      },
      "source": [
        "## 8. Compilación del Modelo\n",
        "\n",
        "**Explicación:** La compilación define la función de pérdida y el optimizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_code_compile"
      },
      "outputs": [],
      "source": [
        "# Compilación del modelo\n",
        "modelo_entrenamiento.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es0WTcr_7sDk"
      },
      "source": [
        "## 9. Entrenamiento del Modelo\n",
        "\n",
        "**Explicación:** Durante el entrenamiento, se utiliza teacher forcing para proporcionar la salida correcta en cada paso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aonkoj3z7sDk"
      },
      "outputs": [],
      "source": [
        "# Parámetros de entrenamiento\n",
        "épocas = 2  # Limitado a 2 para ejecución rápida en clase; en casa usar 20 o más\n",
        "tamaño_lote = 64\n",
        "\n",
        "historial = modelo_entrenamiento.fit(\n",
        "    [entrada_encoder_entren, entrada_decoder_entren],\n",
        "    objetivo_decoder_entren[:, :, np.newaxis],  # Dimensión para loss\n",
        "    batch_size=tamaño_lote,\n",
        "    epochs=épocas,\n",
        "    validation_data=([entrada_encoder_val, entrada_decoder_val], objetivo_decoder_val[:, :, np.newaxis])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfl1ked7sDk"
      },
      "source": [
        "## 10. Gráfico del Historial de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wBvGG847sDk"
      },
      "outputs": [],
      "source": [
        "# Función para graficar historial\n",
        "def graficar_historial_entrenamiento(historial):\n",
        "    # Gráfico de precisión\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(historial.history['accuracy'], 'bo-', label='Entrenamiento')\n",
        "    plt.plot(historial.history['val_accuracy'], 'ro-', label='Validación')\n",
        "    plt.title('Precisión del Modelo')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Gráfico de pérdida\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(historial.history['loss'], 'bo-', label='Entrenamiento')\n",
        "    plt.plot(historial.history['val_loss'], 'ro-', label='Validación')\n",
        "    plt.title('Pérdida del Modelo')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "graficar_historial_entrenamiento(historial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTrVy5lS7sDl"
      },
      "source": [
        "## 11. Modelos para Inferencia\n",
        "\n",
        "**Explicación:** Durante la inferencia, el decoder genera token por token, utilizando sus predicciones previas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9VEX4vD7sDl"
      },
      "outputs": [],
      "source": [
        "# Modelo encoder para inferencia\n",
        "modelo_encoder = Model(entradas_encoder, estados_encoder)\n",
        "\n",
        "# Entradas de estados para decoder\n",
        "entradas_estados_decoder = [Input(shape=(unidades_ocultas,)), Input(shape=(unidades_ocultas,))]\n",
        "entrada_simple_decoder = Input(shape=(1,))\n",
        "incrustacion_simple_decoder = capa_incrustacion_decoder(entrada_simple_decoder)\n",
        "\n",
        "# Reutilización de LSTM decoder\n",
        "salidas_decoder, estado_h, estado_c = lstm_decoder(incrustacion_simple_decoder, initial_state=entradas_estados_decoder)\n",
        "estados_decoder = [estado_h, estado_c]\n",
        "\n",
        "# Reutilización de capa densa\n",
        "salidas_decoder = densa_decoder(salidas_decoder)\n",
        "\n",
        "# Modelo decoder para inferencia\n",
        "modelo_decoder = Model([entrada_simple_decoder] + entradas_estados_decoder, [salidas_decoder] + estados_decoder)\n",
        "\n",
        "modelo_encoder.summary()\n",
        "modelo_decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0WuCVi7sDl"
      },
      "source": [
        "## 12. Función para Decodificar Secuencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRO-gDUC7sDl"
      },
      "outputs": [],
      "source": [
        "# Índices inversos para decodificación\n",
        "índice_char_entrada_inverso = dict((i, palabra) for palabra, i in tokenizador_entrada.word_index.items())\n",
        "índice_char_objetivo_inverso = dict((i, palabra) for palabra, i in tokenizador_objetivo.word_index.items())\n",
        "\n",
        "# Función de decodificación\n",
        "def decodificar_secuencia(sec_entrada):\n",
        "    # Obtención de estados del encoder\n",
        "    valores_estados = modelo_encoder.predict(sec_entrada, verbose=0)\n",
        "    # Secuencia objetivo inicial con start\n",
        "    sec_objetivo = np.zeros((1, 1))\n",
        "    sec_objetivo[0, 0] = tokenizador_objetivo.word_index['start']\n",
        "\n",
        "    condición_paro = False\n",
        "    oración_decodificada = ''\n",
        "\n",
        "    # Bucle de generación autoregresiva\n",
        "    while not condición_paro:\n",
        "        tokens_salida, h, c = modelo_decoder.predict([sec_objetivo] + valores_estados, verbose=0)\n",
        "        índice_token_muestreado = np.argmax(tokens_salida[0, -1, :])\n",
        "        char_muestreada = índice_char_objetivo_inverso.get(índice_token_muestreado, '<des>')\n",
        "\n",
        "        # Condición de salida\n",
        "        if (char_muestreada == 'end' or len(oración_decodificada.split()) > longitud_máx_objetivo):\n",
        "            condición_paro = True\n",
        "        else:\n",
        "            oración_decodificada += ' ' + char_muestreada\n",
        "\n",
        "        # Actualización de secuencia objetivo\n",
        "        sec_objetivo = np.zeros((1, 1))\n",
        "        sec_objetivo[0, 0] = índice_token_muestreado\n",
        "\n",
        "        # Actualización de estados\n",
        "        valores_estados = [h, c]\n",
        "\n",
        "    return oración_decodificada.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Z30-Ht7sDl"
      },
      "source": [
        "## 13. Prueba de Traducciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXOqEI0r7sDm"
      },
      "outputs": [],
      "source": [
        "# Selección de índices aleatorios\n",
        "índices_muestra = np.random.choice(range(len(entrada_encoder_val)), 5, replace=False)\n",
        "resultados = []\n",
        "\n",
        "for i in índices_muestra:\n",
        "    sec_entrada = entrada_encoder_val[i:i+1]\n",
        "    traducción_predicha = decodificar_secuencia(sec_entrada)\n",
        "\n",
        "    # Conversión de secuencias a texto\n",
        "    oración_entrada = ' '.join([índice_char_entrada_inverso.get(i, '') for i in sec_entrada[0] if i != 0])\n",
        "\n",
        "    tokens_oración_objetivo = [índice_char_objetivo_inverso.get(i, '') for i in entrada_decoder_val[i] if i != 0 and i not in [tokenizador_objetivo.word_index.get('start', 0), tokenizador_objetivo.word_index.get('end', 0)]]\n",
        "    oración_objetivo = ' '.join(tokens_oración_objetivo).strip()\n",
        "\n",
        "    resultados.append((oración_entrada, oración_objetivo, traducción_predicha))\n",
        "\n",
        "# Visualización en DataFrame\n",
        "df_resultados = pd.DataFrame(resultados, columns=['Entrada (Inglés)', 'Objetivo (Español)', 'Predicho (Español)'])\n",
        "display(df_resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEADArOo7sDm"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "Se demostró un modelo encoder-decoder básico para traducción automática. Para mejorar el rendimiento, se recomienda agregar mecanismos de atención o utilizar arquitecturas de transformadores.\n",
        "\n",
        "**Actividad Sugerida:** Implementar un mecanismo de atención simple y compare los resultados cualitativos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}